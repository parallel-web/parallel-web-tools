{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Data Enrichment with DuckDB\n",
    "\n",
    "This notebook demonstrates how to use the `parallel-web-tools` package to enrich DuckDB tables using the Parallel API.\n",
    "\n",
    "## Features\n",
    "\n",
    "- **Batch Processing**: Efficient parallel enrichment of entire tables\n",
    "- **SQL UDF**: Row-by-row enrichment via SQL functions\n",
    "- **Multiple processors**: Choose speed vs. depth tradeoff\n",
    "- **Error handling**: Graceful handling with detailed error reporting\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "```bash\n",
    "pip install parallel-web-tools[duckdb]\n",
    "export PARALLEL_API_KEY=\"your-api-key\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed\n",
    "# !pip install parallel-web-tools[duckdb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import duckdb\n",
    "\n",
    "from parallel_web_tools.integrations.duckdb import enrich_table, register_parallel_functions\n",
    "\n",
    "print(f\"DuckDB version: {duckdb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "\n",
    "Set your Parallel API key via environment variable or pass it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file (if present)\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ.get(\"PARALLEL_API_KEY\")\n",
    "if api_key:\n",
    "    print(f\"PARALLEL_API_KEY is set ({len(api_key)} chars)\")\n",
    "else:\n",
    "    print(\"PARALLEL_API_KEY not found. Create a .env file with:\")\n",
    "    print(\"  PARALLEL_API_KEY=your-key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DuckDB connection and sample data\n",
    "conn = duckdb.connect()\n",
    "\n",
    "conn.execute(\"\"\"\n",
    "    CREATE TABLE companies AS SELECT * FROM (VALUES\n",
    "        ('Google', 'google.com', 'Technology'),\n",
    "        ('Microsoft', 'microsoft.com', 'Technology'),\n",
    "        ('Apple', 'apple.com', 'Technology'),\n",
    "        ('Amazon', 'amazon.com', 'E-commerce'),\n",
    "        ('Parallel Web Systems', 'paralell.ai', 'Technology')\n",
    "    ) AS t(company_name, website, industry)\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(\"SELECT * FROM companies\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Batch Enrichment (Recommended)\n",
    "\n",
    "Batch processing is the most efficient approach for multiple rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrich with CEO name and founding year\n",
    "# Note: This will make API calls - may take a few seconds\n",
    "\n",
    "result = enrich_table(\n",
    "    conn,\n",
    "    source_table=\"SELECT company_name, website FROM companies LIMIT 2\",\n",
    "    input_columns={\n",
    "        \"company_name\": \"company_name\",\n",
    "        \"website\": \"website\",\n",
    "    },\n",
    "    output_columns=[\n",
    "        \"CEO name (current CEO or equivalent leader)\",\n",
    "        \"Founding year (YYYY format)\",\n",
    "        \"Brief company description (1-2 sentences)\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"Success: {result.success_count}, Errors: {result.error_count}\")\n",
    "print(f\"Time: {result.elapsed_time:.2f} seconds\")\n",
    "result.result.fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Result\n",
    "\n",
    "The `EnrichmentResult` object contains:\n",
    "- `relation`: DuckDB relation with enriched data\n",
    "- `success_count`: Number of rows successfully enriched\n",
    "- `error_count`: Number of rows that failed\n",
    "- `errors`: List of error details for failed rows\n",
    "- `elapsed_time`: Total processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any errors\n",
    "if result.error_count > 0:\n",
    "    print(\"Errors encountered:\")\n",
    "    for error in result.errors:\n",
    "        print(f\"  Row {error['row']}: {error['error']}\")\n",
    "else:\n",
    "    print(\"All rows enriched successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Name Mapping\n",
    "\n",
    "Output columns are automatically converted to valid SQL identifiers:\n",
    "\n",
    "| Description | Column Name |\n",
    "|-------------|-------------|\n",
    "| `\"CEO name\"` | `ceo_name` |\n",
    "| `\"Founding year (YYYY)\"` | `founding_year` |\n",
    "| `\"Brief company description\"` | `brief_company_description` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the column names\n",
    "print(\"Enriched columns:\", result.result.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Results\n",
    "\n",
    "The result is a DuckDB relation that can be queried further or converted to a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas DataFrame\n",
    "df = result.result.fetchdf()\n",
    "df[[\"company_name\", \"ceo_name\", \"founding_year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use SQL on the relation\n",
    "result.result.filter(\"founding_year IS NOT NULL\").select(\"company_name, founding_year\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress Tracking\n",
    "\n",
    "For large batches, you can track progress with a callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_callback(completed: int, total: int):\n",
    "    pct = 100 * completed / total if total > 0 else 0\n",
    "    print(f\"\\rProgress: {completed}/{total} ({pct:.0f}%)\", end=\"\")\n",
    "\n",
    "\n",
    "# result = enrich_table(\n",
    "#     conn,\n",
    "#     source_table=\"companies\",\n",
    "#     input_columns={\"company_name\": \"company_name\"},\n",
    "#     output_columns=[\"CEO name\"],\n",
    "#     progress_callback=progress_callback,\n",
    "# )\n",
    "# print()  # New line after progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including Citations (Basis)\n",
    "\n",
    "You can include the sources used for enrichment by setting `include_basis=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get enrichment with citations\n",
    "result_with_basis = enrich_table(\n",
    "    conn,\n",
    "    source_table=\"SELECT company_name FROM companies LIMIT 1\",\n",
    "    input_columns={\"company_name\": \"company_name\"},\n",
    "    output_columns=[\"CEO name\"],\n",
    "    include_basis=True,\n",
    ")\n",
    "\n",
    "# Access the basis (citations)\n",
    "df = result_with_basis.result.fetchdf()\n",
    "for _, row in df.iterrows():\n",
    "    print(f\"Company: {row['company_name']}\")\n",
    "    print(f\"CEO: {row['ceo_name']}\")\n",
    "    print(f\"Sources: {row['_basis']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Permanent Tables\n",
    "\n",
    "You can save enriched results to a permanent table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to a permanent table\n",
    "# result = enrich_table(\n",
    "#     conn,\n",
    "#     source_table=\"companies\",\n",
    "#     input_columns={\"company_name\": \"company_name\"},\n",
    "#     output_columns=[\"CEO name\"],\n",
    "#     result_table=\"enriched_companies\",  # Creates permanent table\n",
    "# )\n",
    "#\n",
    "# # Query it later\n",
    "# conn.execute(\"SELECT * FROM enriched_companies\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processor Options\n",
    "\n",
    "Choose a processor based on your needs:\n",
    "\n",
    "| Processor | Speed | Cost | Best For |\n",
    "|-----------|-------|------|----------|\n",
    "| `lite-fast` | Fastest | Lowest | Basic metadata, high volume |\n",
    "| `base-fast` | Fast | Low | Standard enrichments |\n",
    "| `core-fast` | Medium | Medium | Cross-referenced data |\n",
    "| `pro-fast` | Slow | High | Deep research |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a different processor for more depth\n",
    "result_detailed = enrich_table(\n",
    "    conn,\n",
    "    source_table=\"SELECT company_name FROM companies LIMIT 1\",\n",
    "    input_columns={\"company_name\": \"company_name\"},\n",
    "    output_columns=[\n",
    "        \"Recent news headline about this company\",\n",
    "        \"Stock ticker symbol\",\n",
    "    ],\n",
    "    processor=\"base-fast\",  # Use base processor for more depth\n",
    ")\n",
    "\n",
    "result_detailed.result.fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL UDF Approach (Alternative)\n",
    "\n",
    "For simple queries or when you prefer SQL, you can use the registered UDF.\n",
    "Note: This is slower than batch processing for multiple rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the UDF\n",
    "register_parallel_functions(conn, processor=\"lite-fast\")\n",
    "\n",
    "# Use in a query (one row only for demo)\n",
    "results = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        company_name,\n",
    "        parallel_enrich(\n",
    "            json_object('company_name', company_name),\n",
    "            json_array('CEO name')\n",
    "        ) as enriched\n",
    "    FROM companies\n",
    "    LIMIT 1\n",
    "\"\"\").fetchall()\n",
    "\n",
    "# Parse the JSON result\n",
    "for name, enriched_json in results:\n",
    "    data = json.loads(enriched_json)\n",
    "    print(f\"{name}: {data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling\n",
    "\n",
    "Errors in individual rows don't stop the batch processing. Failed rows will have NULL values in enriched columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table with potential errors\n",
    "conn.execute(\"\"\"\n",
    "    CREATE TABLE companies_with_issues AS SELECT * FROM (VALUES\n",
    "        ('Google'),\n",
    "        ('NonexistentCompanyXYZ123')\n",
    "    ) AS t(company_name)\n",
    "\"\"\")\n",
    "\n",
    "result = enrich_table(\n",
    "    conn,\n",
    "    source_table=\"companies_with_issues\",\n",
    "    input_columns={\"company_name\": \"company_name\"},\n",
    "    output_columns=[\"CEO name\"],\n",
    ")\n",
    "\n",
    "print(f\"Success: {result.success_count}, Errors: {result.error_count}\")\n",
    "\n",
    "# Check errors\n",
    "if result.errors:\n",
    "    for error in result.errors:\n",
    "        print(f\"Row {error['row']}: {error['error']}\")\n",
    "\n",
    "# View results (errors show as NULL)\n",
    "result.result.fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "### 1. Use Batch Processing for Multiple Rows\n",
    "\n",
    "```python\n",
    "# Good - uses parallel Task Group API\n",
    "result = enrich_table(conn, \"companies\", ...)\n",
    "\n",
    "# Slower - one API call per row\n",
    "conn.execute(\"SELECT *, parallel_enrich(...) FROM companies\")\n",
    "```\n",
    "\n",
    "### 2. Be Specific in Descriptions\n",
    "\n",
    "```python\n",
    "# Good - specific descriptions\n",
    "output_columns = [\n",
    "    \"CEO name (current CEO or equivalent leader)\",\n",
    "    \"Founding year (YYYY format)\",\n",
    "    \"Annual revenue (USD, most recent fiscal year)\",\n",
    "]\n",
    "\n",
    "# Less specific - may get inconsistent results\n",
    "output_columns = [\"CEO\", \"Year\", \"Revenue\"]\n",
    "```\n",
    "\n",
    "### 3. Use Appropriate Processors\n",
    "\n",
    "- `lite-fast`: Basic metadata, high volume (cheapest)\n",
    "- `base-fast`: Standard company information\n",
    "- `pro-fast`: Deep research requiring multiple sources\n",
    "\n",
    "### 4. Handle Errors Gracefully\n",
    "\n",
    "```python\n",
    "result = enrich_table(conn, ...)\n",
    "if result.error_count > 0:\n",
    "    logger.warning(f\"{result.error_count} rows failed\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- See the [DuckDB Setup Guide](../docs/duckdb-setup.md) for more details\n",
    "- Check [Parallel Documentation](https://docs.parallel.ai) for API information\n",
    "- View [parallel-web-tools on GitHub](https://github.com/parallel-web/parallel-web-tools)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parallel-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
