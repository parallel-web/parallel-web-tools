{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Data Enrichment with Polars\n",
    "\n",
    "This notebook demonstrates how to use the `parallel-web-tools` package to enrich Polars DataFrames using the Parallel API.\n",
    "\n",
    "## Features\n",
    "\n",
    "- **DataFrame-native**: Works directly with Polars DataFrames\n",
    "- **Batch processing**: All rows processed in a single efficient batch\n",
    "- **Multiple processors**: Choose speed vs. depth tradeoff\n",
    "- **Error handling**: Graceful handling with detailed error reporting\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "```bash\n",
    "pip install parallel-web-tools[polars]\n",
    "export PARALLEL_API_KEY=\"your-api-key\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed\n",
    "# !pip install parallel-web-tools[polars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "from parallel_web_tools.integrations.polars import parallel_enrich\n",
    "\n",
    "print(f\"Polars version: {pl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "\n",
    "Set your Parallel API key via environment variable or pass it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file (if present)\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ.get(\"PARALLEL_API_KEY\")\n",
    "if api_key:\n",
    "    print(f\"PARALLEL_API_KEY is set ({len(api_key)} chars)\")\n",
    "else:\n",
    "    print(\"PARALLEL_API_KEY not found. Create a .env file with:\")\n",
    "    print(\"  PARALLEL_API_KEY=your-key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample company data\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"company_name\": [\"Google\", \"Microsoft\", \"Apple\", \"Amazon\", \"Parallel Web Systems\"],\n",
    "        \"website\": [\"google.com\", \"microsoft.com\", \"apple.com\", \"amazon.com\", \"parallel.ai\"],\n",
    "        \"industry\": [\"Technology\", \"Technology\", \"Technology\", \"E-commerce\", \"Technology\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Enrichment\n",
    "\n",
    "Enrich the DataFrame with company information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrich with CEO name and founding year\n",
    "# Note: This will make API calls - may take a few seconds\n",
    "\n",
    "result = parallel_enrich(\n",
    "    df.head(2),  # Start with just 2 rows for demo\n",
    "    input_columns={\n",
    "        \"company_name\": \"company_name\",\n",
    "        \"website\": \"website\",\n",
    "    },\n",
    "    output_columns=[\n",
    "        \"CEO name (current CEO or equivalent leader)\",\n",
    "        \"Founding year (YYYY format)\",\n",
    "        \"Brief company description (1-2 sentences)\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"Success: {result.success_count}, Errors: {result.error_count}\")\n",
    "print(f\"Time: {result.elapsed_time:.2f} seconds\")\n",
    "result.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Result\n",
    "\n",
    "The `EnrichmentResult` object contains:\n",
    "- `dataframe`: The enriched DataFrame with new columns\n",
    "- `success_count`: Number of rows successfully enriched\n",
    "- `error_count`: Number of rows that failed\n",
    "- `errors`: List of error details for failed rows\n",
    "- `elapsed_time`: Total processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any errors\n",
    "if result.error_count > 0:\n",
    "    print(\"Errors encountered:\")\n",
    "    for error in result.errors:\n",
    "        print(f\"  Row {error['row']}: {error['error']}\")\n",
    "else:\n",
    "    print(\"All rows enriched successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Name Mapping\n",
    "\n",
    "Output columns are automatically converted to valid Python identifiers:\n",
    "\n",
    "| Description | Column Name |\n",
    "|-------------|-------------|\n",
    "| `\"CEO name\"` | `ceo_name` |\n",
    "| `\"Founding year (YYYY)\"` | `founding_year` |\n",
    "| `\"Brief company description\"` | `brief_company_description` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the column names\n",
    "print(\"Original columns:\", df.columns)\n",
    "print(\"Enriched columns:\", result.result.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Enriched Data\n",
    "\n",
    "The enriched DataFrame works like any other Polars DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select specific columns\n",
    "result.result.select([\"company_name\", \"ceo_name\", \"founding_year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and transform\n",
    "(\n",
    "    result.result.filter(pl.col(\"founding_year\").is_not_null())\n",
    "    .with_columns(pl.col(\"founding_year\").cast(pl.Int64).alias(\"founded_int\"))\n",
    "    .select([\"company_name\", \"ceo_name\", \"founded_int\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including Citations (Basis)\n",
    "\n",
    "You can include the sources used for enrichment by setting `include_basis=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get enrichment with citations\n",
    "result_with_basis = parallel_enrich(\n",
    "    df.head(1),\n",
    "    input_columns={\"company_name\": \"company_name\"},\n",
    "    output_columns=[\"CEO name\"],\n",
    "    include_basis=True,\n",
    ")\n",
    "\n",
    "# Access the basis (citations)\n",
    "for row in result_with_basis.result.iter_rows(named=True):\n",
    "    print(f\"Company: {row['company_name']}\")\n",
    "    print(f\"CEO: {row['ceo_name']}\")\n",
    "    print(f\"Sources: {row['_basis']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processor Options\n",
    "\n",
    "Choose a processor based on your needs:\n",
    "\n",
    "| Processor | Speed | Cost | Best For |\n",
    "|-----------|-------|------|----------|\n",
    "| `lite-fast` | Fastest | Lowest | Basic metadata, high volume |\n",
    "| `base-fast` | Fast | Low | Standard enrichments |\n",
    "| `core-fast` | Medium | Medium | Cross-referenced data |\n",
    "| `pro-fast` | Slow | High | Deep research |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a different processor for more depth\n",
    "result_detailed = parallel_enrich(\n",
    "    df.head(1),\n",
    "    input_columns={\"company_name\": \"company_name\"},\n",
    "    output_columns=[\n",
    "        \"Recent news headline about this company\",\n",
    "        \"Stock ticker symbol\",\n",
    "    ],\n",
    "    processor=\"base-fast\",  # Use base processor for more depth\n",
    ")\n",
    "\n",
    "result_detailed.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Dataset Processing\n",
    "\n",
    "For large datasets, consider processing in batches to manage API costs and timeouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_in_batches(\n",
    "    df: pl.DataFrame, input_columns: dict, output_columns: list, batch_size: int = 50, **kwargs\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"Process a large DataFrame in batches.\"\"\"\n",
    "    results = []\n",
    "    total_success = 0\n",
    "    total_errors = 0\n",
    "\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.slice(i, batch_size)\n",
    "        print(f\"Processing rows {i} to {i + len(batch)}...\")\n",
    "\n",
    "        result = parallel_enrich(batch, input_columns=input_columns, output_columns=output_columns, **kwargs)\n",
    "\n",
    "        results.append(result.result)\n",
    "        total_success += result.success_count\n",
    "        total_errors += result.error_count\n",
    "\n",
    "    print(f\"\\nTotal: {total_success} success, {total_errors} errors\")\n",
    "    return pl.concat(results)\n",
    "\n",
    "\n",
    "# Example usage (commented out to avoid API calls)\n",
    "# large_df = pl.DataFrame({\"company\": [\"Company \" + str(i) for i in range(100)]})\n",
    "# enriched = enrich_in_batches(\n",
    "#     large_df,\n",
    "#     input_columns={\"company_name\": \"company\"},\n",
    "#     output_columns=[\"CEO name\"],\n",
    "#     batch_size=25\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling\n",
    "\n",
    "Errors in individual rows don't stop the batch processing. Failed rows will have `None` values in enriched columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with potential errors\n",
    "df_with_issues = pl.DataFrame(\n",
    "    {\n",
    "        \"company_name\": [\"Google\", \"NonexistentCompanyXYZ123\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "result = parallel_enrich(\n",
    "    df_with_issues,\n",
    "    input_columns={\"company_name\": \"company_name\"},\n",
    "    output_columns=[\"CEO name\"],\n",
    ")\n",
    "\n",
    "print(f\"Success: {result.success_count}, Errors: {result.error_count}\")\n",
    "\n",
    "# Filter to only successful rows\n",
    "successful_df = result.result.filter(pl.col(\"ceo_name\").is_not_null())\n",
    "successful_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "### 1. Be Specific in Descriptions\n",
    "\n",
    "```python\n",
    "# Good - specific descriptions\n",
    "output_columns = [\n",
    "    \"CEO name (current CEO or equivalent leader)\",\n",
    "    \"Founding year (YYYY format)\",\n",
    "    \"Annual revenue (USD, most recent fiscal year)\",\n",
    "]\n",
    "\n",
    "# Less specific - may get inconsistent results\n",
    "output_columns = [\"CEO\", \"Year\", \"Revenue\"]\n",
    "```\n",
    "\n",
    "### 2. Use Appropriate Processors\n",
    "\n",
    "- `lite-fast`: Basic metadata, high volume (cheapest)\n",
    "- `base-fast`: Standard company information\n",
    "- `pro-fast`: Deep research requiring multiple sources\n",
    "\n",
    "### 3. Handle Errors Gracefully\n",
    "\n",
    "```python\n",
    "result = parallel_enrich(df, ...)\n",
    "if result.error_count > 0:\n",
    "    logger.warning(f\"{result.error_count} rows failed\")\n",
    "```\n",
    "\n",
    "### 4. Consider Batch Sizes\n",
    "\n",
    "For very large datasets (1000+ rows), process in batches to:\n",
    "- Avoid timeout issues\n",
    "- Get partial results faster\n",
    "- Better handle failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- See the [Polars Setup Guide](../docs/polars-setup.md) for more details\n",
    "- Check [Parallel Documentation](https://docs.parallel.ai) for API information\n",
    "- View [parallel-web-tools on GitHub](https://github.com/parallel-web/parallel-web-tools)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parallel-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
