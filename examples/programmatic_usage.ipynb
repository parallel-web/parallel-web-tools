{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Parallel Tools - Programmatic Usage\n\nThis notebook demonstrates how to use `parallel_web_tools` programmatically in your Python code, notebooks, or data pipelines."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, load environment variables and import the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env.local\n",
    "load_dotenv(\"../.env.local\")\n",
    "\n",
    "# Verify API key is loaded\n",
    "if os.getenv(\"PARALLEL_API_KEY\"):\n",
    "    print(\"✓ API key loaded\")\n",
    "else:\n",
    "    print(\"⚠ Warning: PARALLEL_API_KEY not found in .env.local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Run Enrichment from YAML File\n",
    "\n",
    "The simplest way to run enrichment - just point to a YAML config file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parallel_web_tools import run_enrichment\n",
    "\n",
    "# Run enrichment from existing YAML config\n",
    "try:\n",
    "    run_enrichment(\"example_csv_schema.yaml\")\n",
    "    print(\"\\n✓ Enrichment completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Run from Configuration Dictionary\n",
    "\n",
    "Build your configuration programmatically and run it directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parallel_web_tools import run_enrichment_from_dict\n",
    "\n",
    "# Define configuration as a dictionary\n",
    "config = {\n",
    "    \"source\": \"example_file.csv\",\n",
    "    \"target\": \"../data/output_notebook.csv\",\n",
    "    \"source_type\": \"csv\",\n",
    "    \"source_columns\": [\n",
    "        {\"name\": \"business_name\", \"description\": \"The name of a business\"},\n",
    "        {\"name\": \"web_site\", \"description\": \"The business's website URL\"},\n",
    "    ],\n",
    "    \"enriched_columns\": [\n",
    "        {\"name\": \"industry\", \"description\": \"The primary industry or sector of the business\"},\n",
    "        {\"name\": \"employee_count_estimate\", \"description\": \"Estimated number of employees (as a range like '50-100')\"},\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Run the enrichment\n",
    "try:\n",
    "    run_enrichment_from_dict(config)\n",
    "    print(\"\\n✓ Enrichment completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Build Schema Objects Programmatically\n",
    "\n",
    "Use the schema classes directly for full type safety:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parallel_web_tools import Column, InputSchema, SourceType\n",
    "\n",
    "# Build schema programmatically\n",
    "schema = InputSchema(\n",
    "    source=\"example_file.csv\",\n",
    "    target=\"../data/output_schema_based.csv\",\n",
    "    source_type=SourceType.CSV,\n",
    "    source_columns=[\n",
    "        Column(\"business_name\", \"The name of a business\"),\n",
    "        Column(\"web_site\", \"The business's website URL\"),\n",
    "    ],\n",
    "    enriched_columns=[\n",
    "        Column(\"headquarters_location\", \"City and country of company headquarters\"),\n",
    "        Column(\"year_founded\", \"Year the company was founded\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Schema created:\")\n",
    "print(f\"  Source: {schema.source}\")\n",
    "print(f\"  Target: {schema.target}\")\n",
    "print(f\"  Type: {schema.source_type.value}\")\n",
    "print(f\"  Source columns: {[c.name for c in schema.source_columns]}\")\n",
    "print(f\"  Enriched columns: {[c.name for c in schema.enriched_columns]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run the enrichment with our schema\n",
    "from parallel_web_tools.processors import process_csv\n",
    "\n",
    "try:\n",
    "    process_csv(schema)\n",
    "    print(\"\\n✓ Enrichment completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Results\n",
    "\n",
    "Let's look at the enriched data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the enriched CSV\n",
    "df = pd.read_csv(\"../data/output_notebook.csv\")\n",
    "\n",
    "print(f\"\\nEnriched dataset: {len(df)} rows, {len(df.columns)} columns\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Dynamic Configuration Based on Data\n",
    "\n",
    "Build configurations dynamically based on your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read source data to inspect columns\n",
    "source_df = pd.read_csv(\"example_file.csv\")\n",
    "print(f\"Source data columns: {list(source_df.columns)}\")\n",
    "print(f\"Source data shape: {source_df.shape}\")\n",
    "\n",
    "# Dynamically create config based on what we find\n",
    "detected_columns = list(source_df.columns)\n",
    "\n",
    "dynamic_config = {\n",
    "    \"source\": \"example_file.csv\",\n",
    "    \"target\": \"../data/output_dynamic.csv\",\n",
    "    \"source_type\": \"csv\",\n",
    "    \"source_columns\": [{\"name\": col, \"description\": f\"Data from {col} column\"} for col in detected_columns],\n",
    "    \"enriched_columns\": [\n",
    "        {\"name\": \"technology_stack\", \"description\": \"Primary technologies or platforms used by the company\"}\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(f\"\\nDynamic config created with {len(dynamic_config['source_columns'])} source columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Batch Processing Multiple Files\n",
    "\n",
    "Process multiple datasets in a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from parallel_web_tools import run_enrichment\n",
    "\n",
    "# List of config files to process\n",
    "config_files = [\n",
    "    \"example_csv_schema.yaml\",\n",
    "    # Add more configs here\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for config_file in config_files:\n",
    "    config_path = Path(config_file)\n",
    "\n",
    "    if not config_path.exists():\n",
    "        print(f\"⚠ Skipping {config_file} - file not found\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nProcessing: {config_file}\")\n",
    "\n",
    "    try:\n",
    "        run_enrichment(config_file)\n",
    "        results.append({\"config\": config_file, \"status\": \"success\"})\n",
    "        print(\"  ✓ Completed\")\n",
    "    except Exception as e:\n",
    "        results.append({\"config\": config_file, \"status\": \"failed\", \"error\": str(e)})\n",
    "        print(f\"  ✗ Failed: {e}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"Batch processing complete\")\n",
    "print(f\"  Successful: {sum(1 for r in results if r['status'] == 'success')}\")\n",
    "print(f\"  Failed: {sum(1 for r in results if r['status'] == 'failed')}\")\n",
    "print(f\"{'=' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Error Handling and Validation\n",
    "\n",
    "Proper error handling for production use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from parallel_web_tools import ParseError, run_enrichment_from_dict\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def safe_enrichment(config):\n",
    "    \"\"\"\n",
    "    Safely run enrichment with proper error handling.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Starting enrichment: {config['source']} -> {config['target']}\")\n",
    "        run_enrichment_from_dict(config)\n",
    "        logger.info(\"✓ Enrichment completed successfully\")\n",
    "        return {\"success\": True}\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"✗ File not found: {e}\")\n",
    "        return {\"success\": False, \"error\": \"file_not_found\", \"message\": str(e)}\n",
    "\n",
    "    except ParseError as e:\n",
    "        logger.error(f\"✗ Invalid configuration: {e}\")\n",
    "        return {\"success\": False, \"error\": \"invalid_config\", \"message\": str(e)}\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"✗ Unexpected error: {e}\")\n",
    "        return {\"success\": False, \"error\": \"unknown\", \"message\": str(e)}\n",
    "\n",
    "\n",
    "# Test the safe wrapper\n",
    "test_config = {\n",
    "    \"source\": \"example_file.csv\",\n",
    "    \"target\": \"../data/output_safe.csv\",\n",
    "    \"source_type\": \"csv\",\n",
    "    \"source_columns\": [{\"name\": \"business_name\", \"description\": \"Company name\"}],\n",
    "    \"enriched_columns\": [{\"name\": \"ceo_name\", \"description\": \"Name of the CEO\"}],\n",
    "}\n",
    "\n",
    "result = safe_enrichment(test_config)\n",
    "print(f\"\\nResult: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration Example: Use in Data Pipeline\n",
    "\n",
    "Example of how to integrate into a data pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline_with_enrichment():\n",
    "    \"\"\"\n",
    "    Example data pipeline that includes enrichment step.\n",
    "    This could be part of an Airflow DAG, cron job, etc.\n",
    "    \"\"\"\n",
    "    print(\"Step 1: Extract data from source...\")\n",
    "    # Your ETL logic here\n",
    "\n",
    "    print(\"Step 2: Transform data...\")\n",
    "    # Data transformation logic\n",
    "\n",
    "    print(\"Step 3: Enrich data with Parallel...\")\n",
    "    config = {\n",
    "        \"source\": \"example_file.csv\",\n",
    "        \"target\": \"../data/output_pipeline.csv\",\n",
    "        \"source_type\": \"csv\",\n",
    "        \"source_columns\": [\n",
    "            {\"name\": \"business_name\", \"description\": \"Company name\"},\n",
    "        ],\n",
    "        \"enriched_columns\": [\n",
    "            {\"name\": \"description\", \"description\": \"Brief company description\"},\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        run_enrichment_from_dict(config)\n",
    "        print(\"  ✓ Enrichment successful\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Enrichment failed: {e}\")\n",
    "        raise\n",
    "\n",
    "    print(\"Step 4: Load enriched data to destination...\")\n",
    "    # Load to data warehouse, database, etc.\n",
    "\n",
    "    print(\"\\n✓ Pipeline completed successfully!\")\n",
    "\n",
    "\n",
    "# Run the pipeline\n",
    "# data_pipeline_with_enrichment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nYou've learned how to:\n\n1. ✓ Run enrichment from YAML files\n2. ✓ Run enrichment from dictionaries\n3. ✓ Build schemas programmatically with type safety\n4. ✓ Inspect and validate results\n5. ✓ Handle errors gracefully\n6. ✓ Integrate into data pipelines\n7. ✓ Process multiple datasets in batch\n\nFor more information:\n- See `API.md` for complete API reference\n- See `programmatic_usage.py` for standalone Python script examples\n- Run `parallel-cli --help` for CLI usage"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
